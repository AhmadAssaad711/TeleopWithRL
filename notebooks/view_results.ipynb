{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a044d5b6",
   "metadata": {},
   "source": [
    "# Training Results — Q-Learning Pneumatic Teleoperation\n",
    "10,000 episodes training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf1723",
   "metadata": {},
   "outputs": [],
   "source": "import sys, os\nsys.path.insert(0, os.path.join(os.getcwd(), '..'))\nos.chdir(os.path.join(os.getcwd(), '..'))\n\nimport numpy as np\nimport matplotlib\nmatplotlib.use('agg')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Load training log\ndata = np.load('results/old/logs/training_log.npz')\nep_rewards = data['episode_rewards']\neval_rewards = data['eval_rewards']\neval_tracking = data['eval_tracking_rmse'] * 1000  # mm\n\nimport config as cfg\nx_eval = np.arange(1, len(eval_rewards) + 1) * cfg.EVAL_EVERY\n\nprint(f'Episodes: {len(ep_rewards)}')\nprint(f'Eval checkpoints: {len(eval_rewards)}')\nprint(f'Final eval reward: {eval_rewards[-1]:.2f}')\nprint(f'Final tracking RMSE: {eval_tracking[-1]:.2f} mm')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a729f231",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\nfig.suptitle('Q-Learning Training — Bilateral Pneumatic Teleoperation (10k episodes)', fontsize=14, fontweight='bold')\n\n# 1. Episode rewards with moving average\nax = axes[0, 0]\nax.plot(ep_rewards, alpha=0.1, lw=0.5, color='steelblue')\nwindow = 200\nma = np.convolve(ep_rewards, np.ones(window)/window, mode='valid')\nax.plot(np.arange(window-1, len(ep_rewards)), ma, color='navy', lw=2, label=f'MA({window})')\nax.set_xlabel('Episode'); ax.set_ylabel('Total Reward')\nax.set_title('Training Reward Curve')\nax.legend(); ax.grid(True, alpha=0.3)\n\n# 2. Eval mean reward\nax = axes[0, 1]\nax.plot(x_eval, eval_rewards, 'bo-', lw=2, markersize=6)\nax.set_xlabel('Episode'); ax.set_ylabel('Mean Reward')\nax.set_title('Evaluation Reward (higher = better)')\nax.grid(True, alpha=0.3)\n\n# 3. Tracking RMSE\nax = axes[1, 0]\nax.plot(x_eval, eval_tracking, 'ro-', lw=2, markersize=6)\nax.axhline(22.2, color='gray', ls='--', lw=1.5, label='Baseline (no valve) ≈ 22 mm')\nax.set_xlabel('Episode'); ax.set_ylabel('Tracking RMSE [mm]')\nax.set_title('Tracking Error (lower = better)')\nax.legend(); ax.grid(True, alpha=0.3)\n\n# 4. Reward distribution over time\nax = axes[1, 1]\nchunks = np.array_split(ep_rewards, 20)\npositions = np.linspace(250, 9750, 20)\nbp = ax.boxplot([c for c in chunks], positions=positions, widths=350, patch_artist=True)\nfor patch in bp['boxes']:\n    patch.set_facecolor('lightblue')\nax.set_xlabel('Episode'); ax.set_ylabel('Reward')\nax.set_title('Reward Distribution Over Training')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('results/old/plots/training_overview.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829b538",
   "metadata": {},
   "outputs": [],
   "source": "# Run one RL episode and one baseline for comparison\nfrom teleop_env import TeleopEnv\nfrom q_learning_agent import QLearningAgent\n\nenv = TeleopEnv()\nstate_dims = env.get_state_dims()\nagent = QLearningAgent(state_dims, cfg.N_ACTIONS)\nagent.load('results/old/models/q_table.npy')\nagent.epsilon = 0.0\nprint(agent)\n\n# RL episode\nobs, _ = env.reset()\nstate = env.discretise_obs(obs)\ndone = False\nwhile not done:\n    action = agent.select_action(state)\n    obs, _, terminated, truncated, _ = env.step(action)\n    done = terminated or truncated\n    state = env.discretise_obs(obs)\nh_rl = env.render()\n\n# Baseline (zero voltage)\nobs, _ = env.reset()\nzero_act = int(np.argmin(np.abs(cfg.V_LEVELS)))\ndone = False\nwhile not done:\n    _, _, terminated, truncated, _ = env.step(zero_act)\n    done = terminated or truncated\nh_bl = env.render()\n\npe_rl = np.array(h_rl['pos_error']) * 1000\npe_bl = np.array(h_bl['pos_error']) * 1000\nrmse_rl = np.sqrt(np.mean(pe_rl**2))\nrmse_bl = np.sqrt(np.mean(pe_bl**2))\n\nprint(f'\\nRL Tracking RMSE:       {rmse_rl:.2f} mm')\nprint(f'Baseline Tracking RMSE: {rmse_bl:.2f} mm')\nprint(f'Improvement:            {(1 - rmse_rl/rmse_bl)*100:.1f}%')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b34d7a",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(5, 1, figsize=(14, 16), sharex=True)\nfig.suptitle('RL Controller vs Baseline — Episode Comparison', fontsize=14, fontweight='bold')\n\nt_rl = np.array(h_rl['time'])\nt_bl = np.array(h_bl['time'])\n\n# Position tracking\nax = axes[0]\nax.plot(t_rl, np.array(h_rl['x_m'])*1000, 'b-', lw=1.5, label='x_m (master)')\nax.plot(t_rl, np.array(h_rl['x_s'])*1000, 'r-', lw=1.5, label='x_s (slave, RL)')\nax.plot(t_bl, np.array(h_bl['x_s'])*1000, 'r--', lw=1, alpha=0.6, label='x_s (slave, baseline)')\nax.set_ylabel('Position [mm]'); ax.set_title('Position Tracking')\nax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n\n# Pressures\nax = axes[1]\nax.plot(t_rl, np.array(h_rl['P_s1'])/1000, 'b-', lw=1, label='P_s1')\nax.plot(t_rl, np.array(h_rl['P_s2'])/1000, 'r-', lw=1, label='P_s2')\nax.plot(t_rl, np.array(h_rl['P_m1'])/1000, 'b--', lw=0.7, alpha=0.5, label='P_m1')\nax.plot(t_rl, np.array(h_rl['P_m2'])/1000, 'r--', lw=0.7, alpha=0.5, label='P_m2')\nax.set_ylabel('Pressure [kPa]'); ax.set_title('Chamber Pressures (RL)')\nax.legend(fontsize=8); ax.grid(True, alpha=0.3)\n\n# Forces\nax = axes[2]\nax.plot(t_rl, h_rl['F_h'], 'b-', lw=1, label='F_h (human)')\nax.plot(t_rl, h_rl['F_e'], 'r-', lw=1, label='F_e (env, RL)')\nax.plot(t_bl, h_bl['F_e'], 'r--', lw=0.8, alpha=0.5, label='F_e (env, baseline)')\nax.set_ylabel('Force [N]'); ax.set_title('Forces')\nax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n\n# Valve\nax = axes[3]\nax.plot(t_rl, h_rl['u_v'], 'g-', lw=1, label='u_v [V]')\nax2 = ax.twinx()\nax2.plot(t_rl, h_rl['x_v'], 'm-', lw=0.8, alpha=0.7, label='x_v (spool)')\nax.set_ylabel('Valve Voltage [V]'); ax2.set_ylabel('Spool Position')\nax.set_title('Valve Control Signal (RL)')\nlines1, labels1 = ax.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax.legend(lines1+lines2, labels1+labels2, fontsize=9); ax.grid(True, alpha=0.3)\n\n# Tracking error\nax = axes[4]\nax.plot(t_rl, pe_rl, 'b-', lw=1.5, label=f'RL (RMSE={rmse_rl:.1f} mm)')\nax.plot(t_bl, pe_bl, 'r--', lw=1, alpha=0.7, label=f'Baseline (RMSE={rmse_bl:.1f} mm)')\nax.axhline(0, color='gray', lw=0.5)\nax.set_ylabel('Tracking Error [mm]'); ax.set_xlabel('Time [s]')\nax.set_title('Tracking Error (x_m − x_s)')\nax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('results/old/plots/episode_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}